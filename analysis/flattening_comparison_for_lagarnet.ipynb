{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c32a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# HELPER: parse list-like strings\n",
    "# -------------------------------\n",
    "\n",
    "def parse_list(s):\n",
    "    \"\"\"Convert string like '[0.2, 0.1, 0.05]' into list of floats.\"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# METRIC EXTRACTION LOGIC\n",
    "\n",
    "def aggregate_performance(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    df[\"iou_flat\"] = df[\"evaluation/max_IoU_to_flattened\"].apply(parse_list)\n",
    "    df[\"nc\"] = df[\"evaluation/normalised_coverage\"].apply(parse_list)\n",
    "    df[\"ni\"] = df[\"evaluation/normalised_improvement\"].apply(parse_list)\n",
    "    df[\"success_list\"] = df[\"evaluation/success\"].apply(parse_list)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Extract per-row statistics\n",
    "    # ---------------------------\n",
    "\n",
    "\n",
    "    max_nc = [np.max(x) for x in df[\"nc\"]]\n",
    "    last_nc = [x[-1] for x in df[\"nc\"]]\n",
    "    max_ni = [np.max(x) for x in df[\"ni\"]]\n",
    "    last_ni = [x[-1] for x in df[\"ni\"]]\n",
    "\n",
    "    last_max_iou = [x[-1] for x in df[\"iou_flat\"]]\n",
    "    max_max_iou = [np.max(x) for x in df[\"iou_flat\"]]\n",
    "\n",
    "    # ---------------------------\n",
    "    # Success + steps-to-finish\n",
    "    # ---------------------------\n",
    "\n",
    "    first_success_flags = []\n",
    "    final_success_flags = []\n",
    "    steps_to_first_success = []\n",
    "\n",
    "    for success_list in df[\"success_list\"]:\n",
    "        if any(success_list):\n",
    "            first_success_flags.append(1)\n",
    "            steps_to_first_success.append(success_list.index(True))\n",
    "        else:\n",
    "            first_success_flags.append(0)\n",
    "            steps_to_first_success.append(len(success_list) - 1)\n",
    "        if success_list[-1]:\n",
    "            final_success_flags.append(1)\n",
    "        else:\n",
    "            final_success_flags.append(0)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Aggregated metrics (means)\n",
    "    # ---------------------------\n",
    "\n",
    "\n",
    "    max_iou_mean = np.mean(max_max_iou)\n",
    "    #max_iou_flat_mean = np.mean(max_iou_flat)\n",
    "    last_iou_mean = np.mean(last_max_iou)\n",
    "    max_nc_mean = np.mean(max_nc)\n",
    "    max_ni_mean = np.mean(max_ni)\n",
    "    last_nc_mean = np.mean(max_nc)\n",
    "    last_ni_mean = np.mean(max_ni)\n",
    "\n",
    "    first_success_rate = np.mean(first_success_flags)\n",
    "    final_success_rate = np.mean(final_success_flags)\n",
    "    print('final_success_flags', final_success_flags)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Standard deviations\n",
    "    # ---------------------------\n",
    "    #max_iou_flat_std = np.std(max_iou_flat)\n",
    "\n",
    "    max_iou_std = np.std(max_max_iou)\n",
    "    last_iou_std = np.std(last_max_iou)\n",
    "\n",
    "    max_nc_std = np.std(max_nc)\n",
    "    max_ni_std = np.std(max_ni)\n",
    "\n",
    "    last_nc_std = np.mean(last_nc)\n",
    "    last_ni_std = np.mean(last_ni)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Episode counts\n",
    "    # ---------------------------\n",
    "\n",
    "    num_episodes = len(df)\n",
    "    first_success_episodes = int(np.sum(first_success_flags))\n",
    "    final_success_episodes = int(np.sum(final_success_flags))\n",
    "    steps_to_finish_mean = np.mean(steps_to_first_success)\n",
    "    steps_to_finish_std = np.std(steps_to_first_success)\n",
    "\n",
    "    return {\n",
    "        # Means\n",
    "\n",
    "        \"max_IoU_mean\": max_iou_mean,\n",
    "        #\"max_IoU_to_flattened_mean\": max_iou_flat_mean,\n",
    "        \"max_NC_mean\": max_nc_mean, \n",
    "        \"max_NI_std\": max_ni_mean,\n",
    "        \"last_IoU_mean\": last_iou_mean,\n",
    "        \"last_NC_mean\": last_nc_mean,\n",
    "        \"last_NI_mean\": last_ni_mean,\n",
    "        \"steps_to_first_success_mean\": steps_to_finish_mean,\n",
    "\n",
    "        # Standard deviations\n",
    "        \"max_IoU_std\": max_iou_std,\n",
    "        \"last_IoU_std\": last_iou_std,\n",
    "        \"last_NC_std\": last_nc_std,\n",
    "        \"last_NI_std\": last_ni_std,\n",
    "        #\"max_IoU_to_flattened_std\": max_iou_flat_std,\n",
    "        \"steps_to_first_success_std\": steps_to_finish_std,\n",
    "        \"max_NC_std\": max_nc_std, \n",
    "        \"max_NI_std\": max_ni_std, \n",
    "\n",
    "        # Others\n",
    "        \"first_success_rate\": first_success_rate,\n",
    "        \"final_success_rate\": final_success_rate,\n",
    "        \"num_episodes\": num_episodes,\n",
    "        \"first_success_episodes\": first_success_episodes,\n",
    "        \"final_success_episodes\": final_success_episodes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4040bb3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We evaluate the ability to flattening, ablilty to folding and ability to recover from failed folding states.\n",
    "# first success in a trajectory --> ability to folding\n",
    "# final step success in a trajectory --> ability to recognise success and recover from failures.\n",
    "\n",
    "data_dir = \"/media/hcv530/T7/garment_folding_data\"\n",
    "experiments = [\n",
    "    {\n",
    "        \"name\": \"diffusion_single_picker_single_primitive_multi_longsleeve_flattening_demo_50\",\n",
    "        \"label\": \"Diffusion-Demo-50\",\n",
    "        \"check\": \"eval_checkpoint_50000\"\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"diffusion_single_picker_single_primitive_multi_longsleeve_flattening_demo_100\",\n",
    "        \"label\": \"Diffusion-Demo-100\",\n",
    "        \"check\": \"eval_checkpoint_-2\"\n",
    "    },\n",
    "\n",
    "    {\n",
    "        \"name\": \"lagarnet_single_picker_single_primitive_multi_longsleeve_flattening_sanity_check\",\n",
    "        \"label\": \"All Garment LaGarNet\\nfrom 50-demo Diffusion\",\n",
    "        \"check\": \"eval_checkpoint_-2\"\n",
    "    }, \n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for exp in experiments:\n",
    "    csv_path = os.path.join(\n",
    "        data_dir,\n",
    "        exp[\"name\"],\n",
    "        exp[\"check\"],\n",
    "        \"performance.csv\"\n",
    "    )\n",
    "    print('csv', csv_path)\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"WARNING: Missing file: {csv_path}\")\n",
    "        continue\n",
    "    \n",
    "\n",
    "    metrics = aggregate_performance(csv_path)\n",
    "    metrics[\"experiment\"] = exp[\"label\"]\n",
    "    rows.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "cols = [\"experiment\"] + [c for c in results_df.columns if c != \"experiment\"]\n",
    "results_df = results_df[cols]\n",
    "display(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03bd4571",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib\n",
    "# matplotlib.use(\"Agg\")  # non-interactive, stable\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "# List of metrics you want to plot (base names without _mean / _std)\n",
    "metrics = [\n",
    "    \"max_IoU\",\n",
    "    \"last_IoU\",\n",
    "    \"max_NC\",\n",
    "    \"steps_to_first_success\",\n",
    "]\n",
    "\n",
    "experiments = results_df[\"experiment\"]\n",
    "\n",
    "for metric in metrics:\n",
    "    mean_col = f\"{metric}_mean\"\n",
    "    std_col = f\"{metric}_std\"\n",
    "\n",
    "    means = results_df[mean_col]\n",
    "    stds = results_df[std_col]\n",
    "\n",
    "    x = np.arange(len(experiments))\n",
    "\n",
    "    plt.figure(figsize=(10, 4))\n",
    "    plt.bar(x, means, yerr=stds, capsize=5)\n",
    "    plt.xticks(x, experiments)\n",
    "    plt.ylabel(metric.replace(\"_\", \" \"))\n",
    "    plt.title(f\"{metric.replace('_', ' ').title()}\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac16ac41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "experiments = results_df[\"experiment\"]\n",
    "num_episodes = results_df[\"num_episodes\"]\n",
    "\n",
    "# Success rates\n",
    "first_success = results_df[\"first_success_rate\"]\n",
    "final_success = results_df[\"final_success_rate\"]\n",
    "\n",
    "x = np.arange(len(experiments))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.bar(\n",
    "    x - bar_width / 2,\n",
    "    first_success,\n",
    "    bar_width,\n",
    "    capsize=5,\n",
    "    label=\"First Success\",\n",
    ")\n",
    "\n",
    "plt.bar(\n",
    "    x + bar_width / 2,\n",
    "    final_success,\n",
    "    bar_width,\n",
    "    capsize=5,\n",
    "    label=\"Final Success\",\n",
    ")\n",
    "\n",
    "plt.xticks(x, experiments)\n",
    "plt.ylabel(\"Success Rate\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.legend()\n",
    "plt.title(\"First vs Final Success Rate\")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f0ae8e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "experiments = results_df[\"experiment\"]\n",
    "num_episodes = results_df[\"num_episodes\"]\n",
    "\n",
    "# Metrics\n",
    "max_iou_flat = results_df[\"max_IoU_mean\"]\n",
    "max_nc = results_df[\"max_NC_mean\"]\n",
    "\n",
    "# Standard error\n",
    "max_iou_flat_se = results_df[\"max_IoU_std\"]\n",
    "max_nc_se = results_df[\"max_NC_std\"]\n",
    "\n",
    "x = np.arange(len(experiments))\n",
    "bar_width = 0.35\n",
    "\n",
    "plt.figure(figsize=(10, 4))\n",
    "\n",
    "plt.bar(\n",
    "    x - bar_width/2,\n",
    "    max_iou_flat,\n",
    "    bar_width,\n",
    "    yerr=max_iou_flat_se,\n",
    "    capsize=5,\n",
    "    label=\"Max IoU to Flattened\",\n",
    ")\n",
    "\n",
    "plt.bar(\n",
    "    x + bar_width/2,\n",
    "    max_nc,\n",
    "    bar_width,\n",
    "    yerr=max_nc_se,\n",
    "    capsize=5,\n",
    "    label=\"Max NC\",\n",
    ")\n",
    "\n",
    "plt.xticks(x, experiments)\n",
    "plt.ylabel(\"Value\")\n",
    "plt.ylim(0, 1.05)\n",
    "plt.title(\"Max IoU to Flattened vs Max NC\")\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80296f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the metrics and whether they have a std column\n",
    "metrics = [\n",
    "    (\"steps_to_first_success\", True),  # has _mean and _std\n",
    "    (\"first_success_rate\", False),     # no _mean, no _std\n",
    "    (\"final_success_rate\", False),     # no _mean, no _std\n",
    "    (\"last_IoU\", True),\n",
    "    (\"max_NC\", True),\n",
    "    (\"max_IoU\", True),\n",
    "]\n",
    "\n",
    "# Column labels for LaTeX\n",
    "column_labels = [\n",
    "    \"S2F(\\#)\",\n",
    "    \"1st-SR (\\%)\",\n",
    "    \"Final-SR (\\%)\",\n",
    "    \"LM-IoU (Fold, \\%)\",\n",
    "    \"Max NC (\\%)\",\n",
    "    \"MM-IoU (Flat, \\%)\",\n",
    "]\n",
    "\n",
    "# Metrics to scale by 100\n",
    "scale_100 = [\"first_success_rate\", \"final_success_rate\", \n",
    "             \"last_IoU\", \"max_NC\", \"max_IoU\"]\n",
    "\n",
    "# Start LaTeX table\n",
    "latex_table = \"\\\\begin{tabular}{l\" + \"c\"*len(metrics) + \"}\\n\"\n",
    "latex_table += \"Experiment & \" + \" & \".join(column_labels) + \" \\\\\\\\\\n\"\n",
    "latex_table += \"\\\\hline\\n\"\n",
    "\n",
    "for idx, row in results_df.iterrows():\n",
    "    row_values = []\n",
    "    for metric, has_std in metrics:\n",
    "        factor = 100 if metric in scale_100 else 1\n",
    "        if has_std and f\"{metric}_mean\" in results_df.columns:\n",
    "            mean_val = row[f\"{metric}_mean\"] * factor\n",
    "            std_val = row[f\"{metric}_std\"] * factor\n",
    "            row_values.append(f\"${mean_val:.1f} \\\\pm {std_val:.1f}$\")\n",
    "        else:\n",
    "            val = row[metric] * factor\n",
    "            row_values.append(f\"{val:.1f}\")\n",
    "    latex_table += f\"{row['experiment']} & \" + \" & \".join(row_values) + \" \\\\\\\\\\n\"\n",
    "\n",
    "latex_table += \"\\\\end{tabular}\"\n",
    "\n",
    "print(latex_table)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mp-fold",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
