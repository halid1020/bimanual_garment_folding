{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "233ab67f",
   "metadata": {},
   "source": [
    "We compare minimum average particle distance acorss trajecotry, last-step average particle distance across trajecotries, minimum average semantic distance across trajecotries, last-step average particle distance across trajectories, max_IoU agains the goal, automatically detected SR. We fix the trajecotry horizon as 20 regardless if it reaches success or not. Because, we also want to test the policies capability not to mess the success states. The evalaution arena should not have readjust pick assistance.\n",
    "\n",
    "TODO:\n",
    "1. Regenerate the oracle folding with fixed 20 horizon.\n",
    "2. Generate the huma policy\n",
    "3. in hydra train and eval, seperate the train trajectory setup from the eval trajecotry setup, because some algo needs the reajust-pick assistance.\n",
    "    * use ray-capsulated arena for pyflex."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "22c32a2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import ast\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# HELPER: parse list-like strings\n",
    "# -------------------------------\n",
    "\n",
    "def parse_list(s):\n",
    "    \"\"\"Convert string like '[0.2, 0.1, 0.05]' into list of floats.\"\"\"\n",
    "    if isinstance(s, list):\n",
    "        return s\n",
    "    return ast.literal_eval(s)\n",
    "\n",
    "\n",
    "# -------------------------------\n",
    "# METRIC EXTRACTION LOGIC\n",
    "\n",
    "def aggregate_performance(csv_path):\n",
    "    df = pd.read_csv(csv_path)\n",
    "\n",
    "    # Convert list-like string columns to actual lists\n",
    "    df[\"particle_dist\"] = df[\"evaluation/mean_particle_distance\"].apply(parse_list)\n",
    "    df[\"semantic_dist\"] = df[\"evaluation/semantic_keypoint_distance\"].apply(parse_list)\n",
    "    df[\"iou\"] = df[\"evaluation/max_IoU\"].apply(parse_list)\n",
    "    df[\"iou_flat\"] = df[\"evaluation/max_IoU_to_flattened\"].apply(parse_list)\n",
    "    df[\"nc\"] = df[\"evaluation/normalised_coverage\"].apply(parse_list)\n",
    "    df[\"success_list\"] = df[\"evaluation/success\"].apply(parse_list)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Extract per-row statistics\n",
    "    # ---------------------------\n",
    "\n",
    "    min_particle_distance = [np.min(x) for x in df[\"particle_dist\"]]\n",
    "    min_semantic_distance = [np.min(x) for x in df[\"semantic_dist\"]]\n",
    "\n",
    "    max_max_iou = [np.max(x) for x in df[\"iou\"]]\n",
    "    max_iou_flat = [np.max(x) for x in df[\"iou_flat\"]]\n",
    "    max_nc = [np.max(x) for x in df[\"nc\"]]\n",
    "\n",
    "    last_particle_distance = [x[-1] for x in df[\"particle_dist\"]]\n",
    "    last_semantic_distance = [x[-1] for x in df[\"semantic_dist\"]]\n",
    "    last_max_iou = [x[-1] for x in df[\"iou\"]]\n",
    "\n",
    "    # ---------------------------\n",
    "    # Success + steps-to-finish\n",
    "    # ---------------------------\n",
    "\n",
    "    first_success_flags = []\n",
    "    final_success_flags = []\n",
    "    steps_to_first_success = []\n",
    "\n",
    "    for success_list in df[\"success_list\"]:\n",
    "        if any(success_list):\n",
    "            first_success_flags.append(1)\n",
    "            steps_to_first_success.append(success_list.index(True))\n",
    "        else:\n",
    "            first_success_flags.append(0)\n",
    "            steps_to_first_success.append(len(success_list) - 1)\n",
    "        if success_list[-1]:\n",
    "            final_success_flags.append(1)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Aggregated metrics (means)\n",
    "    # ---------------------------\n",
    "\n",
    "    min_particle_mean = np.mean(min_particle_distance)\n",
    "    last_particle_mean = np.mean(last_particle_distance)\n",
    "\n",
    "    min_semantic_mean = np.mean(min_semantic_distance)\n",
    "    last_semantic_mean = np.mean(last_semantic_distance)\n",
    "\n",
    "    max_iou_mean = np.mean(max_max_iou)\n",
    "    max_iou_flat_mean = np.mean(max_iou_flat)\n",
    "    last_iou_mean = np.mean(last_max_iou)\n",
    "    max_nc_mean = np.mean(max_nc)\n",
    "\n",
    "    first_success_rate = np.mean(first_success_flags)\n",
    "    final_success_rate = np.mean(final_success_flags)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Standard deviations\n",
    "    # ---------------------------\n",
    "\n",
    "    min_particle_std = np.std(min_particle_distance)\n",
    "    last_particle_std = np.std(last_particle_distance)\n",
    "\n",
    "    min_semantic_std = np.std(min_semantic_distance)\n",
    "    last_semantic_std = np.std(last_semantic_distance)\n",
    "\n",
    "    max_iou_std = np.std(max_max_iou)\n",
    "    last_iou_std = np.std(last_max_iou)\n",
    "\n",
    "    max_nc_std = np.std(max_nc)\n",
    "\n",
    "    # ---------------------------\n",
    "    # Episode counts\n",
    "    # ---------------------------\n",
    "\n",
    "    num_episodes = len(df)\n",
    "    first_success_episodes = int(np.sum(first_success_rate))\n",
    "    final_success_episodes = int(np.sum(final_success_rate))\n",
    "    steps_to_finish_mean = np.mean(steps_to_first_success)\n",
    "    steps_to_finish_std = np.std(steps_to_first_success)\n",
    "\n",
    "    return {\n",
    "        # Means\n",
    "        \"min_particle_distance_mean\": min_particle_mean,\n",
    "        \"last_particle_distance_mean\": last_particle_mean,\n",
    "        \"min_semantic_distance_mean\": min_semantic_mean,\n",
    "        \"last_semantic_distance_mean\": last_semantic_mean,\n",
    "        \"max_IoU_mean\": max_iou_mean,\n",
    "        \"max_IoU_to_flattened_mean\": max_iou_flat_mean,\n",
    "        \"max_NC_mean\": max_nc_mean, \n",
    "        \"last_IoU_mean\": last_iou_mean,\n",
    "        \"steps_to_first_success_mean\": steps_to_finish_mean,\n",
    "\n",
    "        # Standard deviations\n",
    "        \"min_particle_distance_std\": min_particle_std,\n",
    "        \"last_particle_distance_std\": last_particle_std,\n",
    "        \"min_semantic_distance_std\": min_semantic_std,\n",
    "        \"last_semantic_distance_std\": last_semantic_std,\n",
    "        \"max_IoU_std\": max_iou_std,\n",
    "        \"last_IoU_std\": last_iou_std,\n",
    "        \"steps_to_first_success_std\": steps_to_finish_std,\n",
    "        \"max_NC_std\": max_nc_std, \n",
    "\n",
    "        # Others\n",
    "        \"first_success_rate\": first_success_rate,\n",
    "        \"final_success_rate\": final_success_rate,\n",
    "        \"num_episodes\": num_episodes,\n",
    "        \"first_success_episodes\": first_success_episodes,\n",
    "        \"final_success_episodes\": final_success_episodes\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4040bb3f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "csv /mnt/ssd/garment_folding_data/human_multi_primitive_multi_longsleeve_folding_from_crumpled/eval_checkpoint_-1/performance.csv\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>experiment</th>\n",
       "      <th>min_particle_distance_mean</th>\n",
       "      <th>last_particle_distance_mean</th>\n",
       "      <th>min_semantic_distance_mean</th>\n",
       "      <th>last_semantic_distance_mean</th>\n",
       "      <th>max_IoU_mean</th>\n",
       "      <th>max_IoU_to_flattened_mean</th>\n",
       "      <th>max_NC_mean</th>\n",
       "      <th>last_IoU_mean</th>\n",
       "      <th>steps_to_first_success_mean</th>\n",
       "      <th>...</th>\n",
       "      <th>last_semantic_distance_std</th>\n",
       "      <th>max_IoU_std</th>\n",
       "      <th>last_IoU_std</th>\n",
       "      <th>steps_to_first_success_std</th>\n",
       "      <th>max_NC_std</th>\n",
       "      <th>first_success_rate</th>\n",
       "      <th>final_success_rate</th>\n",
       "      <th>num_episodes</th>\n",
       "      <th>first_success_episodes</th>\n",
       "      <th>final_success_episodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Human</td>\n",
       "      <td>0.063959</td>\n",
       "      <td>0.063959</td>\n",
       "      <td>0.059834</td>\n",
       "      <td>0.059834</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>0.865817</td>\n",
       "      <td>0.951157</td>\n",
       "      <td>0.884821</td>\n",
       "      <td>8.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005295</td>\n",
       "      <td>0.009173</td>\n",
       "      <td>0.009173</td>\n",
       "      <td>0.942809</td>\n",
       "      <td>0.015806</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows Ã— 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  experiment  min_particle_distance_mean  last_particle_distance_mean  \\\n",
       "0      Human                    0.063959                     0.063959   \n",
       "\n",
       "   min_semantic_distance_mean  last_semantic_distance_mean  max_IoU_mean  \\\n",
       "0                    0.059834                     0.059834      0.884821   \n",
       "\n",
       "   max_IoU_to_flattened_mean  max_NC_mean  last_IoU_mean  \\\n",
       "0                   0.865817     0.951157       0.884821   \n",
       "\n",
       "   steps_to_first_success_mean  ...  last_semantic_distance_std  max_IoU_std  \\\n",
       "0                     8.333333  ...                    0.005295     0.009173   \n",
       "\n",
       "   last_IoU_std  steps_to_first_success_std  max_NC_std  first_success_rate  \\\n",
       "0      0.009173                    0.942809    0.015806                 1.0   \n",
       "\n",
       "   final_success_rate  num_episodes  first_success_episodes  \\\n",
       "0                 1.0             3                       1   \n",
       "\n",
       "   final_success_episodes  \n",
       "0                       1  \n",
       "\n",
       "[1 rows x 23 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# We evaluate the ability to flattening, ablilty to folding and ability to recover from failed folding states.\n",
    "# first success in a trajectory --> ability to folding\n",
    "# final step success in a trajectory --> ability to recognise success and recover from failures.\n",
    "\n",
    "data_dir = \"/mnt/ssd/garment_folding_data\"\n",
    "experiments = [\n",
    "    {\n",
    "        \"name\": \"human_multi_primitive_multi_longsleeve_folding_from_crumpled\",\n",
    "        \"label\": \"Human\"\n",
    "    }\n",
    "]\n",
    "\n",
    "rows = []\n",
    "\n",
    "for exp in experiments:\n",
    "    csv_path = os.path.join(\n",
    "        data_dir,\n",
    "        exp[\"name\"],\n",
    "        \"eval_checkpoint_-1\",\n",
    "        \"performance.csv\"\n",
    "    )\n",
    "    print('csv', csv_path)\n",
    "    if not os.path.exists(csv_path):\n",
    "        print(f\"WARNING: Missing file: {csv_path}\")\n",
    "        continue\n",
    "\n",
    "    metrics = aggregate_performance(csv_path)\n",
    "    metrics[\"experiment\"] = exp[\"label\"]\n",
    "    rows.append(metrics)\n",
    "\n",
    "results_df = pd.DataFrame(rows)\n",
    "cols = [\"experiment\"] + [c for c in results_df.columns if c != \"experiment\"]\n",
    "results_df = results_df[cols]\n",
    "display(results_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "agent-arena-v0",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
