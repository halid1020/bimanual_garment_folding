name: dreamerV3
logdir: null
traindir: null
evaldir: null
offline_traindir: ''
offline_evaldir: ''
seed: 0
deterministic_run: False
steps: 1e5
parallel: False
# eval_every: 1e4
# eval_episode_num: 10
log_every: 1e2
reset_every: 0
device: 'cuda:0'
compile: True
precision: 32
debug: False
train_video_pred_log: True


# time_limit: 1000
grayscale: False

reward_EMA: True

# Model
dyn_hidden: 512
dyn_deter: 512
dyn_stoch: 32
dyn_discrete: 32
dyn_rec_depth: 1
dyn_mean_act: 'none'
dyn_std_act: 'sigmoid2'
dyn_min_std: 0.1
grad_heads: ['decoder', 'reward', 'cont']
units: 512
act: 'SiLU'
norm: True
encoder:
  {mlp_keys: '$^', cnn_keys: 'image', act: 'SiLU', norm: True, cnn_depth: 32, kernel_size: 4, minres: 4, mlp_layers: 5, mlp_units: 1024, symlog_inputs: True}
decoder:
  {mlp_keys: '$^', cnn_keys: 'image', act: 'SiLU', norm: True, cnn_depth: 32, kernel_size: 4, minres: 4, mlp_layers: 5, mlp_units: 1024, cnn_sigmoid: False, image_dist: mse, vector_dist: symlog_mse, outscale: 1.0}
actor:
  {layers: 2, dist: 'normal', entropy: 3e-4, unimix_ratio: 0.01, std: 'learned', min_std: 0.1, max_std: 1.0, temp: 0.1, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 1.0}
critic:
  {layers: 2, dist: 'symlog_disc', slow_target: True, slow_target_update: 1, slow_target_fraction: 0.02, lr: 3e-5, eps: 1e-5, grad_clip: 100.0, outscale: 0.0}
reward_head:
  {layers: 2, dist: 'symlog_disc', loss_scale: 1.0, outscale: 0.0}
cont_head:
  {layers: 2, loss_scale: 1.0, outscale: 1.0}
dyn_scale: 0.5
rep_scale: 0.1
kl_free: 1.0
weight_decay: 0.0
unimix_ratio: 0.01
initial: 'learned'

# Training
batch_size: 64 #16
batch_length: 16 #64
train_ratio: 512
pretrain: 100
model_lr: 1e-4
opt_eps: 1e-8
grad_clip: 1000
updates_per_step: 10 #1

opt: 'adam'

# Behavior.
discount: 0.997
discount_lambda: 0.95
imag_horizon: 4 #15
imag_gradient: 'dynamics'
imag_gradient_mix: 0.0
eval_state_mean: False

# Exploration
expl_behavior: 'greedy'
expl_until: 0
expl_extr_scale: 0.0
expl_intr_scale: 1.0
disag_target: 'stoch'
disag_log: True
disag_models: 10
disag_offset: 1
disag_layers: 4
disag_units: 400
disag_action_cond: False

restart: true
# evaluate_method: 'simulate'
# eval_video_pred_log: true


dataset_size: 100000
total_update_steps: 1e5 #This is action steps actually in dreamer
eval_checkpoint: -1
size: [64, 64]
action_repeat: 1
prefill: 250
validation_interval: 1000
obs_keys: ['image', 'is_first', 'is_terminal']
reward_key: coverage_alignment_with_stretch_and_affordance_penalty_high_coverage_bonus
primitive_integration: 'predict_bin_as_output'
primitives:
  - name: norm-pixel-pick-and-fling
    dim: 4 # [pick_0, pick_1]name: image2state-sac
  - name: norm-pixel-fold
    dim: 8 #params: [pick_0, pick_1, place_0, place_1]
save_success: True
num_actions: 'to_be_defined'

exp_name: ${exp_name}
project_name: ${project_name}