name: lagarnet
device: 'cuda:0'
debug: True
train_mode: 'offline'

input_obs: "rgb"
output_obs: "mask"

deterministic_latent_dim: 300 ## 200
stochastic_latent_dim: 60 ## 30
action_dim: 5
hidden_dim: 300 ## 200
embedding_dim: 1024
min_std_dev: 0.1
activation: 'relu'
trans_layers: 1
input_obs_dim: [3, 64, 64]
output_obs_dim: [1, 64, 64]
encoder_batchnorm: False
encoder_residual: False
decoder_batchnorm: False
decoder_residual: False
no_op: [0, 0, 0, 0, 0]
free_nats: 1
symlog: False
# data_sampler: "count-based"

state_layers: 2
observation_scale: 1.0
reward_scale: 1.0
reward_gradient_stop: False
kl_balance: 0.8
kl_scale: 1.0
kl_balancing: True
reward_layers: 5 #3

overshooting_distance: 2  
kl_overshooting_scale: 0.1
kl_overshooting_warmup: True
kl_overshooting_balance: 1.0
reward_overshooting_scale: 0.1
reward_overshooting_warmup: False

optimiser_class: 'adam'
optimiser_params: 
  lr: 1e-3
  eps: 1e-4
grad_clip_norm: 1000

batch_size: 50
sequence_size: 50
total_update_steps: 50001
test_interval: 1000
validation_interval: 1000

refresh_init_state: False

# action_output:
#   norm-pixel-pick-and-place:
#     pick_0: [0, 1]
#     place_0: [2, 3]

apply_transform_in_dataset: True

dataloader_workers: 0
dataloader_prefetch_factor: 1

apply_reward_processor: True

data_augmenter: "identity" #"pick_and_place_transformer_v1_for_lagarnet"
  


encoder_mode: "default"
cost_fn: "trajectory_return"

logger_name: "pick_and_place_fabric_single_task_logger"


datasets:
  - key: 'train'

    name: 'default'
    params:
      data_path: 'noisy_oracle_raven_pixel_packing_boxes' #'diffusion_policy_on_softgym|domain:cloth-funnel-real2sim-longsleeve,task:flattening,horizon:20'
      data_dir: './data/datasets/'
      seq_length: 50
      cross_trajectory: True
      split_ratios: [0.01, 0.01, 0.98]
      cache_in_memory: False
      io_mode: 'r'
      sample_mode: 'train'
      obs_config: 
        mask: 
          shape: [64, 64, 1]
          output_key: 'mask'
        rgb:
          shape: [64, 64, 3]
          output_key: 'rgb'
        goal-mask: 
          shape: [64, 64, 1]
          output_key: 'goal-mask'
        goal-rgb:
          shape: [64, 64, 3]
          output_key: 'goal-rgb'
        default:
          shape: [1]
          output_key: 'reward'
      
      act_config:
        norm-pixel-pick-and-place: 
          shape: [5]
          output_key: 'default'
      

  - key: 'test'

    name: 'default'
    params:
      data_path: 'noisy_oracle_raven_pixel_packing_boxes'
      data_dir: './data/datasets/'
      seq_length: 20
      cross_trajectory: False
      io_mode: 'r'
      sample_mode: 'eval'
      split_ratios: [0.01, 0.01, 0.98]
      sample_terminal: True
      obs_config: 
        mask: 
          shape: [64, 64, 1]
          output_key: 'mask'
        rgb:
          shape: [64, 64, 3]
          output_key: 'rgb'
        goal-mask: 
          shape: [64, 64, 1]
          output_key: 'goal-mask'
        goal-rgb:
          shape: [64, 64, 3]
          output_key: 'goal-rgb'
        default:
          shape: [1]
          output_key: 'reward'

      
      act_config:
        norm-pixel-pick-and-place: 
          shape: [5]
          output_key: 'default'

    

policy:
  name: 'single_arm_mask_pick_and_place_mpc'
  params:
    candidates: 5000
    planning_horizon: 1
    iterations: 100
    clip: True
    swap_action: False
    obj_mask: "from_env"
    debug: True
    cost_fn: 'from_model'
    place_orien: True


test_horizons: [1, 2, 4] # This shoulud be smaller than action horizon.
action_horizon: 50
eval_episodes: 100
eval_action_horizon: 20
eval_save_latent: True